# conflicts in observation class:
class observation:
    """The observation class.
    
    A class with information and data from an observational dataset.
    """

    def __init__(self):
        """Initialize an :class:`observation` object."""
        self.obs = None
        self.label = None
        self.file = None
        self.obj = None
        """The data object (:class:`pandas.DataFrame` or :class:`xarray.Dataset`)."""
        self.type = None
        self.data_proc = None
        self.variable_dict = None

    def __repr__(self):
        return (
            f"{type(self).__name__}(\n"
            f"    obs={self.obs!r},\n"
            f"    label={self.label!r},\n"
            f"    file={self.file!r},\n"
            f"    obj={repr(self.obj) if self.obj is None else '...'},\n"
            f"    type={self.type!r},\n"
            f"    type={self.data_proc!r},\n"
            f"    variable_dict={self.variable_dict!r},\n"
            ")"
        )

    def open_obs(self, time_interval=None):
        """Open the observational data, store data in observation pair,
        and apply mask and scaling.

        Parameters
        __________
        time_interval (optional, default None) : [pandas.Timestamp, pandas.Timestamp]
            If not None, restrict obs to datetime range spanned by time interval [start, end].

        Returns
        -------
        None
        """
        from glob import glob
        from numpy import sort
 
        try:
            if os.path.isfile(self.file):
                _, extension = os.path.splitext(self.file)
                if extension in {'.nc', '.ncf', '.netcdf', '.nc4'}:
                    if len(files) > 1:
                        self.obj = xr.open_mfdataset(files)
                    else:
                        self.obj = xr.open_dataset(files[0])
                elif extension in ['.ict', '.icarrt']:
                    assert len(files) == 1, "monetio.icarrt.add_data can only read one file"
                    self.obj = mio.icarrt.add_data(files[0])
                else:
                    raise ValueError(f'extension {extension!r} currently unsupported')
        except Exception as e:
            print('something happened opening file:', e)
            return

        self.mask_and_scale()  # mask and scale values from the control values
        self.filter_obs()
            
    def open_sat_obs(self):
        """Methods to opens satellite data observations. 
        Uses in-house python code to open and load observations.
        Alternatively may use the satpy reader.
        Returns
        -------
        type
            Fills the object class associated with the equivalent label (self.label) with satellite observation
            dataset read in from the associated file (self.file) by the satellite file reader
        """
        try:
            if self.label == 'omps_l3':
                self.obj = mio.sat._omps_l3_mm.read_OMPS_l3(self.file)
            elif self.label == 'omps_nm':
                self.obj = mio.sat._omps_nadir_mm.read_OMPS_nm(self.file)
            elif self.label == 'mopitt_l3':
                print('Reading MOPITT')
                self.obj = mio.sat._mopitt_l3_mm.read_mopittdataset(self.file, 'column')
            elif self.label == 'modis_l2':
                from monetio import modis_l2
                print('Reading MODIS L2')
                self.obj = modis_l2.read_mfdataset(
                    self.file, self.variable_dict, debug=self.debug)
            elif self.label == 'tropomi_l2_no2':
                from monetio import tropomi_l2_no2
                print('Reading TROPOMI L2 NO2')
                self.obj = tropomi_l2_no2.read_trpdataset(
                    self.file, self.variable_dict, debug=self.debug)
            else: print('file reader not implemented for {} observation'.format(self.label))
        except ValueError:
            print('something happened opening file')
        
    def filter_obs(self):
        """Filter observations based on filter_dict.
        
        Returns
        -------
        None
        """
        if self.data_proc is not None:
            if 'filter_dict' in self.data_proc:
                filter_dict = self.data_proc['filter_dict']
                for column in filter_dict.keys():
                    filter_vals = filter_dict[column]['value']
                    filter_op = filter_dict[column]['oper']
                    if filter_op == 'isin':
                        self.obj = self.obj.where(self.obj[column].isin(filter_vals),drop=True)
                    elif filter_op == 'isnotin':
                        self.obj = self.obj.where(~self.obj[column].isin(filter_vals),drop=True)
                    elif filter_op == '==':
                        self.obj = self.obj.where(self.obj[column] == filter_vals,drop=True)
                    elif filter_op == '>':
                        self.obj = self.obj.where(self.obj[column] > filter_vals,drop=True)
                    elif filter_op == '<':
                        self.obj = self.obj.where(self.obj[column] < filter_vals,drop=True)
                    elif filter_op == '>=':
                        self.obj = self.obj.where(self.obj[column] >= filter_vals,drop=True)
                    elif filter_op == '<=':
                        self.obj = self.obj.where(self.obj[column] <= filter_vals,drop=True)
                    elif filter_op == '!=':
                        self.obj = self.obj.where(self.obj[column] != filter_vals,drop=True)
                    else:
                        raise ValueError(f'Filter operation {filter_op!r} is not supported')


# lines 937-947 block                        
        import matplotlib.pyplot as plt
        obs_to_pair = list(self.models[(list(self.models.keys()))[0]].mapping.keys())[0]
        if self.obs[obs_to_pair].obs_type.lower() == 'pt_sfc': 
            from .plots import surfplots as splots,savefig
        else:
            from .plots import satplots as splots,savefig             
                        
                        
# lines 1094-1135 block and a little bit below for context/little mix-up in merge.
                        # Drop sites with greater than X percent NAN values
                        if 'rem_obs_by_nan_pct' in grp_dict['data_proc']:
                            grp_var = grp_dict['data_proc']['rem_obs_by_nan_pct']['group_var']
                            pct_cutoff = grp_dict['data_proc']['rem_obs_by_nan_pct']['pct_cutoff']
                            
                            if grp_dict['data_proc']['rem_obs_by_nan_pct']['times'] == 'hourly':
                                # Select only hours at the hour
                                hourly_pairdf_all = pairdf_all.reset_index().loc[pairdf_all.reset_index()['time'].dt.minute==0,:]
                                
                                # calculate total obs count, obs count with nan removed, and nan percent for each group
                                grp_fullcount = hourly_pairdf_all[[grp_var,obsvar]].groupby(grp_var).size().rename({0:obsvar})
                                grp_nonan_count = hourly_pairdf_all[[grp_var,obsvar]].groupby(grp_var).count() # counts only non NA values    
                            else: 
                                # calculate total obs count, obs count with nan removed, and nan percent for each group
                                grp_fullcount = pairdf_all[[grp_var,obsvar]].groupby(grp_var).size().rename({0:obsvar})
                                grp_nonan_count = pairdf_all[[grp_var,obsvar]].groupby(grp_var).count() # counts only non NA values  
                                
                            grp_pct_nan = 100 - grp_nonan_count.div(grp_fullcount,axis=0)*100

                            # make list of sites meeting condition and select paired data by this by this
                            grp_select = grp_pct_nan.query(obsvar + ' < ' + str(pct_cutoff)).reset_index()
                            pairdf_all = pairdf_all.loc[pairdf_all[grp_var].isin(grp_select[grp_var].values)]
                        
                        # Drop NaNs if using pandas 
                        if self.obs[obs_to_pair].obs_type.lower() == 'pt_sfc':
                            if grp_dict['data_proc']['rem_obs_nan'] == True:
                                # I removed drop=True in reset_index in order to keep 'time' as a column.
                                pairdf = pairdf_all.reset_index().dropna(subset=[modvar, obsvar])
                            else:
                                print('Warning: set rem_obs_nan = True for regulatory metrics') 
                                pairdf = pairdf_all.reset_index().dropna(subset=[modvar])
                        elif self.obs[obs_to_pair].obs_type.lower() in  ["sat_swath_sfc", "sat_swath_clm", 
                                                                        "sat_grid_sfc", "sat_grid_clm", 
                                                                        "sat_swath_prof"]: 
                            # xarray doesn't need nan drop because its math operations ignore nans. 
                            # MEB 5/18/23: do need to add logic to ensure model data has nans where obs data does
                            pairdf = pairdf_all

                        # JianHe: do we need provide a warning if pairdf is empty (no valid obsdata) for specific subdomain?
                        # MEB: pairdf.empty fails for data left in xarray format. isnull format works.
                        if pairdf[obsvar].isnull().all():
                            print('Warning: no valid obs found for '+domain_name)
                            continue

                        # JianHe: Determine if calculate regulatory values
                        cal_reg = obs_plot_dict.get('regulatory', False)

                        if cal_reg:
                            # Reset use_ylabel for regulatory calculations
                            if 'ylabel_reg_plot' in obs_plot_dict.keys():
                                use_ylabel = obs_plot_dict['ylabel_reg_plot']
                            else:
                                use_ylabel = None

                            df2 = (
                                pairdf.copy()
                                .groupby("siteid")
                                .resample('H', on='time_local')
                                .mean()
                                .reset_index()
                            )
    